# OpenBrewery Data Pipeline

## ğŸ“Œ Sobre o projeto

Este projeto implementa um **pipeline de dados end-to-end** para ingestÃ£o, transformaÃ§Ã£o e modelagem analÃ­tica de dados da [Open Brewery DB API](https://www.openbrewerydb.org/), seguindo a arquitetura **Medallion (Bronze â†’ Silver â†’ Gold)**.

A orquestraÃ§Ã£o Ã© feita com **Apache Airflow** containerizado via **Docker Compose**, as transformaÃ§Ãµes rodam no **Databricks** via PySpark, e a camada Gold Ã© modelada com **dbt**.

---

## ğŸ—ï¸ Arquitetura

```
AIRFLOW (Docker)
      â†“ orquestra
      â”œâ”€â†’ Bronze: ingestÃ£o da API â†’ Databricks (bronze.openbrewery_raw)
      â”œâ”€â†’ Silver: transformaÃ§Ã£o PySpark â†’ Databricks (silver.openbrewery)
      â””â”€â†’ Gold: modelagem dbt â†’ Databricks (gold.gold_openbrewery)
```

### Camadas

- ğŸŸ¤ **Bronze** â€” dados brutos da API em formato Delta, sem transformaÃ§Ãµes
- ğŸŸ  **Silver** â€” dados limpos, tipados, sem duplicatas, particionados por `country` e `state`
- ğŸŸ¢ **Gold** â€” view agregada com contagem de cervejarias por tipo e localizaÃ§Ã£o, pronta para consumo analÃ­tico

---

## ğŸ§± Estrutura do projeto

```text
openbrewery-data-pipeline/
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ openbrewery_pipeline.py       # DAG principal
â”œâ”€â”€ databricks/
â”‚   â”œâ”€â”€ bronze/
â”‚   â”‚   â”œâ”€â”€ bronze_job.ipynb              # Notebook de entrada
â”‚   â”‚   â””â”€â”€ ingest_openbrewery_bronze.py  # LÃ³gica de ingestÃ£o
â”‚   â””â”€â”€ silver/
â”‚       â”œâ”€â”€ silver_job.ipynb              # Notebook de entrada
â”‚       â””â”€â”€ transform_openbrewery_silver.py # LÃ³gica de transformaÃ§Ã£o
â”œâ”€â”€ dbt/
â”‚   â””â”€â”€ openbrewery/
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â””â”€â”€ example/
â”‚       â”‚       â””â”€â”€ gold/
â”‚       â”‚           â”œâ”€â”€ gold_openbrewery.sql
â”‚       â”‚           â””â”€â”€ gold_openbrewery.yml
â”‚       â”œâ”€â”€ sources/
â”‚       â”‚   â””â”€â”€ silver.yml
â”‚       â””â”€â”€ dbt_project.yml
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_bronze.py                    # Testes unitÃ¡rios da camada bronze
â”‚   â””â”€â”€ test_silver.py                    # Testes unitÃ¡rios da camada silver
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â””â”€â”€ .env                                  # VariÃ¡veis de ambiente (nÃ£o versionado)
```

---

## ğŸ› ï¸ PrÃ©-requisitos

- [Docker](https://www.docker.com/) & Docker Compose instalados
- Conta e workspace no [Databricks](https://databricks.com/)
- Token de autenticaÃ§Ã£o do Databricks
- Python 3.10+

---

## ğŸš€ Como Rodar

### 1. Clonar o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/openbrewery-data-pipeline.git
cd openbrewery-data-pipeline
```

### 2. Configurar variÃ¡veis de ambiente

Crie um arquivo `.env` na raiz do projeto:

```env
DATABRICKS_HOST=seu-workspace.cloud.databricks.com
DATABRICKS_HTTP_PATH=/sql/1.0/warehouses/seu-warehouse-id
DATABRICKS_TOKEN=seu-token-aqui
```

### 3. Subir o Airflow

```bash
docker compose up -d --build
```

Acesse `http://localhost:8080` com as credenciais:
- **UsuÃ¡rio:** `admin`
- **Senha:** `admin`

### 4. Configurar a Connection do Databricks no Airflow

1. VÃ¡ em **Admin â†’ Connections**
2. Edite ou crie a connection `databricks_default`:
   - **Conn Type:** Databricks
   - **Host:** `https://seu-workspace.cloud.databricks.com`
   - **Extra:** `{"token": "seu-token-aqui"}`

### 5. Criar os Jobs no Databricks

No workspace do Databricks, crie dois jobs apontando para os notebooks:
- **Bronze:** `databricks/bronze/bronze_job`
- **Silver:** `databricks/silver/silver_job`

Atualize os `job_id` no arquivo `airflow/dags/openbrewery_pipeline.py`.

### 6. Disparar o pipeline

Na UI do Airflow, ative a DAG `openbrewery_pipeline` e clique em **â–¶ Trigger DAG**.

---

## ğŸ§ª Testes

Os testes unitÃ¡rios cobrem as funÃ§Ãµes de ingestÃ£o e transformaÃ§Ã£o das camadas Bronze e Silver.

### Instalar dependÃªncias

```bash
pip install pytest pytest-mock pyspark
```

### Rodar os testes

```bash
pytest tests/ -v
```

---

## ğŸ“ DecisÃµes de Design

| DecisÃ£o | Justificativa |
|---|---|
| Airflow em Docker | Facilita reprodutibilidade e portabilidade do ambiente |
| Databricks para Bronze e Silver | PySpark nativo para processamento distribuÃ­do e armazenamento Delta |
| dbt para Gold | SeparaÃ§Ã£o clara entre transformaÃ§Ã£o de dados e modelagem analÃ­tica |
| Particionamento por `country` e `state` | Melhora performance em queries filtradas por localizaÃ§Ã£o |
| Modo `overwrite` nas escritas | Garante idempotÃªncia â€” reexecutar o pipeline nÃ£o gera duplicatas |
| VariÃ¡veis de ambiente para credenciais | Nenhuma credencial Ã© versionada no repositÃ³rio |

---

## ğŸ“Š Monitoramento e Alertas

### Monitoramento do Pipeline

**Airflow** oferece monitoramento nativo da DAG:
- Cada task tem status visual (success, failed, running) na UI
- O histÃ³rico de execuÃ§Ãµes fica disponÃ­vel em **Browse â†’ DAG Runs**
- Retries automÃ¡ticos podem ser configurados por task:

```python
bronze = DatabricksRunNowOperator(
    task_id="bronze_ingestion",
    retries=3,
    retry_delay=timedelta(minutes=5),
    ...
)
```

### Alertas por E-mail em caso de falha

O Airflow suporta alertas automÃ¡ticos por e-mail configurando `email_on_failure`:

```python
default_args = {
    "email": ["seu-email@example.com"],
    "email_on_failure": True,
    "email_on_retry": False,
}
```

Em produÃ§Ã£o, isso seria integrado com um servidor SMTP ou serviÃ§o como SendGrid.

### Qualidade de Dados

A qualidade dos dados Ã© validada em duas camadas:

**dbt tests na camada Gold:**
- `not_null` nos campos crÃ­ticos (`state`, `brewery_type`, `breweries_count`)
- `accepted_values` para garantir que `brewery_type` contÃ©m apenas valores vÃ¡lidos da API

**Testes unitÃ¡rios no cÃ³digo Python:**
- ValidaÃ§Ã£o de schema e tipos de dados
- VerificaÃ§Ã£o de remoÃ§Ã£o de duplicatas e nulos

### Em produÃ§Ã£o, o monitoramento seria complementado com:

- **Databricks Job Alerts** â€” notificaÃ§Ãµes nativas por e-mail ou webhook quando um job falha
- **Logs centralizados** â€” integraÃ§Ã£o com ferramentas como Datadog ou CloudWatch para agregaÃ§Ã£o de logs
- **Data Quality com Great Expectations** â€” validaÃ§Ãµes mais granulares como verificar volume mÃ­nimo de registros, distribuiÃ§Ã£o de valores, e freshness dos dados
- **SLA Misses no Airflow** â€” alertas quando uma DAG nÃ£o termina dentro do tempo esperado

---

## ğŸ”„ Trade-offs

- **SQLite como metastore do Airflow** â€” adequado para desenvolvimento local, mas em produÃ§Ã£o deve ser substituÃ­do por PostgreSQL para suportar execuÃ§Ãµes paralelas e persistÃªncia de dados entre reinicializaÃ§Ãµes.
- **Serverless compute no Databricks** â€” simplifica a configuraÃ§Ã£o, mas em produÃ§Ã£o seria avaliado um cluster dedicado para workloads previsÃ­veis e maior controle de custo.
- **dbt rodando no container do Airflow** â€” funciona para este projeto, mas em escala seria mais adequado usar o **dbt Cloud** ou um container dedicado para isolamento de dependÃªncias.